#!/usr/bin/env bash
set -e

echo "ðŸ“¦ Creando archivo de JARs de Spark para YARN..."

SPARK_HOME=/opt/spark
HADOOP_HOME=/opt/hadoop
HDFS_JAR_PATH=/spark-jars
LOCAL_TAR=/tmp/spark-libs.tgz

# Esperar a que HDFS estÃ© disponible
echo "â³ Esperando a que HDFS estÃ© disponible..."
until $HADOOP_HOME/bin/hdfs dfs -test -d / >/dev/null 2>&1; do
    sleep 2
done

# Verificar si el archivo ya existe en HDFS
if $HADOOP_HOME/bin/hdfs dfs -test -e $HDFS_JAR_PATH/spark-libs.tgz; then
    echo "âœ… spark-libs.tgz ya existe en HDFS, omitiendo creaciÃ³n"
    exit 0
fi

echo "ðŸ”¨ Empaquetando JARs de Spark..."
cd $SPARK_HOME/jars
tar -czf $LOCAL_TAR *.jar

echo "ðŸ“Š TamaÃ±o del archivo: $(du -h $LOCAL_TAR | cut -f1)"

echo "ðŸ“¤ Subiendo a HDFS..."
$HADOOP_HOME/bin/hdfs dfs -mkdir -p $HDFS_JAR_PATH
$HADOOP_HOME/bin/hdfs dfs -put -f $LOCAL_TAR $HDFS_JAR_PATH/

echo "ðŸ”§ Configurando permisos..."
$HADOOP_HOME/bin/hdfs dfs -chmod 644 $HDFS_JAR_PATH/spark-libs.tgz

echo "âœ… spark-libs.tgz creado exitosamente en HDFS"

# Limpiar archivo temporal
rm -f $LOCAL_TAR

# Verificar
echo "ðŸ“‹ VerificaciÃ³n:"
$HADOOP_HOME/bin/hdfs dfs -ls -h $HDFS_JAR_PATH/
