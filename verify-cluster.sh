#!/bin/bash

echo "ğŸ” Verificando Cluster HDFS con 2 DataNodes"
echo "==========================================="

echo ""
echo "ğŸ“Š Estado de contenedores:"
docker-compose ps

echo ""
echo "â³ Esperando que los servicios estÃ©n listos..."
sleep 30

echo ""
echo "ğŸ“ˆ Reporte detallado de HDFS:"
docker exec namenode hdfs dfsadmin -report

echo ""
echo "ğŸ“‹ Resumen de DataNodes:"
docker exec namenode hdfs dfsadmin -report | grep -A 10 "Live datanodes"

echo ""
echo "ğŸŒ Interfaces web disponibles:"
echo "   - Hadoop UI: http://localhost:9870"
echo "   - Spark Master: http://localhost:8080"
echo "   - Jupyter Lab: http://localhost:8888"

echo ""
echo "ğŸ§ª Prueba rÃ¡pida de HDFS:"
echo "   Creando archivo de prueba..."
echo "Hola desde cluster con 2 DataNodes!" | docker exec -i namenode hdfs dfs -put - /test-2-nodes.txt 2>/dev/null

if docker exec namenode hdfs dfs -cat /test-2-nodes.txt >/dev/null 2>&1; then
    echo "   âœ… Archivo creado y leÃ­do correctamente"
    echo "   ğŸ“„ Contenido: $(docker exec namenode hdfs dfs -cat /test-2-nodes.txt)"
else
    echo "   â³ HDFS aÃºn no estÃ¡ completamente listo"
fi

echo ""
echo "âœ… VerificaciÃ³n completada!"