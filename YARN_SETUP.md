# Gu√≠a de Configuraci√≥n YARN

## üìã Resumen de Cambios

Se ha configurado **Apache YARN** (Yet Another Resource Negotiator) en tu cluster Hadoop para permitir la ejecuci√≥n de trabajos Spark en modo distribuido.

## üéØ Componentes Instalados

### 1. **YARN ResourceManager** (en `namenode`)
- Puerto Web UI: `8088`
- Puerto RPC: `8032`
- Gestiona recursos del cluster
- Programa tareas en NodeManagers

### 2. **YARN NodeManager** (en `datanode1` y `datanode2`)
- Puerto Web UI: `8042` (datanode1), `8043` (datanode2)
- Ejecuta contenedores de aplicaciones
- Reporta recursos al ResourceManager

### 3. **MapReduce JobHistory Server** (en `namenode`)
- Puerto Web UI: `19888`
- Historial de trabajos MapReduce

## üìÅ Archivos Creados/Modificados

### Nuevos Archivos de Configuraci√≥n:
- `config/yarn-site.xml` - Configuraci√≥n YARN
- `config/mapred-site.xml` - Configuraci√≥n MapReduce

### Archivos Actualizados:
- `docker-compose.yml` - Agregadas configuraciones YARN y puertos
- `scripts/start-services-fixed.sh` - Scripts para iniciar servicios YARN
- `notebooks/Proyecto_V1 copy.ipynb` - Configuraci√≥n Spark con YARN

## üöÄ C√≥mo Usar

### 1. Reconstruir y Levantar el Cluster

```powershell
# Detener servicios actuales
docker-compose down

# Reconstruir im√°genes (solo si cambiaste el Dockerfile)
docker-compose build

# Levantar todos los servicios
docker-compose up -d

# Ver logs para verificar que todo inici√≥ correctamente
docker-compose logs -f namenode
```

### 2. Verificar que YARN est√° Funcionando

#### Verificar ResourceManager:
```powershell
# Ver logs del ResourceManager
docker-compose logs namenode | Select-String -Pattern "resourcemanager"

# Acceder a la UI web
# Abrir navegador: http://localhost:8088
```

#### Verificar NodeManagers:
```powershell
# Ver NodeManagers registrados
docker exec -it namenode bash -c "sudo -u hadoop /opt/hadoop/bin/yarn node -list"

# UI de NodeManager 1: http://localhost:8042
# UI de NodeManager 2: http://localhost:8043
```

### 3. Usar YARN desde Jupyter Notebook

Tu notebook ya est√° configurado. Solo ejecuta las celdas:

```python
# Celda 2: Imports (incluye os)
from pyspark.sql import SparkSession
from pyspark.sql.functions import expr, col, lit
from pyspark.sql.functions import col, count, avg, sum, max, min, when, datediff, current_date
import re
import os

# Celda 3: Inicializar Spark con YARN
os.environ['HADOOP_CONF_DIR'] = '/opt/hadoop/etc/hadoop'
os.environ['YARN_CONF_DIR'] = '/opt/hadoop/etc/hadoop'

spark = SparkSession.builder \
    .appName("HDFS_NiFi_Data_Cleaning") \
    .master("yarn") \
    .config("spark.submit.deployMode", "client") \
    .config("spark.hadoop.fs.defaultFS", "hdfs://namenode:9000") \
    .config("spark.yarn.am.memory", "1g") \
    .config("spark.executor.memory", "1g") \
    .config("spark.executor.cores", "1") \
    .config("spark.executor.instances", "2") \
    .getOrCreate()

print(f"‚úÖ Spark Session creada exitosamente")
print(f"üìä Spark Master: {spark.sparkContext.master}")
```

### 4. Monitorear Aplicaciones Spark

- **YARN ResourceManager UI**: http://localhost:8088
  - Ver aplicaciones en ejecuci√≥n
  - Ver aplicaciones completadas
  - Ver recursos del cluster

- **Spark UI** (cuando ejecutes c√≥digo): http://localhost:4040
  - Detalles de jobs
  - Stages y tasks
  - Ejecutores activos

## üîß Configuraci√≥n de Recursos

### Configuraci√≥n Actual (ajustable en `yarn-site.xml`):

- **Memoria por NodeManager**: 4096 MB
- **CPU cores por NodeManager**: 2 vcores
- **Memoria m√≠nima por contenedor**: 512 MB
- **Memoria m√°xima por contenedor**: 4096 MB

### Ajustar Recursos de Spark:

En tu notebook, puedes modificar:

```python
spark = SparkSession.builder \
    .master("yarn") \
    .config("spark.yarn.am.memory", "1g")      # Memoria del Application Master
    .config("spark.executor.memory", "1g")     # Memoria por executor
    .config("spark.executor.cores", "1")       # Cores por executor
    .config("spark.executor.instances", "2")   # N√∫mero de executors
    .getOrCreate()
```

## üêõ Troubleshooting

### Problema: "HADOOP_CONF_DIR or YARN_CONF_DIR must be set"

**Soluci√≥n**: Las variables ya est√°n configuradas en `docker-compose.yml` para el contenedor `jupyter`. Si el error persiste:

```python
import os
os.environ['HADOOP_CONF_DIR'] = '/opt/hadoop/etc/hadoop'
os.environ['YARN_CONF_DIR'] = '/opt/hadoop/etc/hadoop'
```

### Problema: NodeManagers no se registran

**Verificar logs**:
```powershell
docker-compose logs datanode1 | Select-String -Pattern "nodemanager"
docker-compose logs datanode2 | Select-String -Pattern "nodemanager"
```

**Reiniciar NodeManagers**:
```powershell
docker-compose restart datanode1 datanode2
```

### Problema: Aplicaci√≥n Spark falla por falta de memoria

**Reducir recursos**:
```python
.config("spark.executor.memory", "512m") \
.config("spark.executor.instances", "1") \
```

## üìä Comparaci√≥n: Local vs Standalone vs YARN

| Modo | Configuraci√≥n | Uso |
|------|--------------|-----|
| **Local** | `.master("local[*]")` | Desarrollo r√°pido, testing |
| **Standalone** | `.master("spark://spark-master:7077")` | Cluster Spark dedicado |
| **YARN** | `.master("yarn")` | Integraci√≥n Hadoop, compartir recursos |

## ‚úÖ Verificaci√≥n Final

```powershell
# 1. Verificar servicios corriendo
docker-compose ps

# 2. Verificar YARN ResourceManager
curl http://localhost:8088

# 3. Verificar NodeManagers registrados
docker exec -it namenode bash -c "sudo -u hadoop /opt/hadoop/bin/yarn node -list"

# 4. Ejecutar celda de Spark en Jupyter
# Debe mostrar: "Spark Master: yarn"
```

## üéâ Resultado Esperado

Cuando ejecutes tu notebook con YARN:
- ‚úÖ Spark se conecta a YARN
- ‚úÖ YARN crea contenedores en los NodeManagers
- ‚úÖ Los datos se procesan de forma distribuida
- ‚úÖ Puedes monitorear en http://localhost:8088

## üìö Recursos Adicionales

- YARN UI: http://localhost:8088
- HDFS UI: http://localhost:9870
- Spark Master UI: http://localhost:8080
- Jupyter: http://localhost:8888
- MapReduce JobHistory: http://localhost:19888
