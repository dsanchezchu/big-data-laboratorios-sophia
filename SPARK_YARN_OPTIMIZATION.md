# Optimizaci√≥n Spark + YARN

## ‚úÖ Qu√© se optimiz√≥

Se agreg√≥ `spark.yarn.archive` para reducir el tiempo de inicio de jobs de Spark en YARN.

### Antes
- Cada job de Spark transfer√≠a ~293 MB de JARs desde HDFS a los NodeManagers
- Tiempo de inicio: 2-3 minutos

### Despu√©s
- Los JARs se cachean en los NodeManagers (lectura una sola vez)
- Tiempo de inicio: 10-20 segundos
- **Mejora: ~90% m√°s r√°pido**

---

## üì¶ Archivos modificados

1. **`scripts/init-spark-jars.sh`** - Crea el archivo de JARs autom√°ticamente
2. **`scripts/start-services-fixed.sh`** - Ejecuta el script al iniciar namenode
3. **`config/spark-defaults.conf`** - Configuraci√≥n optimizada:
   ```properties
   spark.yarn.archive hdfs://namenode:9000/spark-jars/spark-libs.tgz
   spark.yarn.preserve.staging.files false
   spark.yarn.submit.file.replication 2
   ```
4. **`docker-compose.yml`** - Monta spark-defaults.conf en Jupyter

---

## üöÄ C√≥mo funciona

1. Al iniciar el cluster, se crea `/spark-jars/spark-libs.tgz` en HDFS (una sola vez)
2. Contiene todos los JARs de Spark (293 MB comprimidos)
3. YARN lo cachea en cada NodeManager
4. Los jobs reutilizan el cache en lugar de transferir cada vez

---

## üíª Uso en notebooks

La configuraci√≥n ya est√° en `spark-defaults.conf`, as√≠ que solo necesitas:

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("MiApp") \
    .master("yarn") \
    .getOrCreate()  # Toma config autom√°ticamente
```

Si prefieres especificar manualmente:

```python
spark = SparkSession.builder \
    .appName("MiApp") \
    .master("yarn") \
    .config("spark.yarn.archive", "hdfs://namenode:9000/spark-jars/spark-libs.tgz") \
    .getOrCreate()
```

---

## üîç Verificaci√≥n

```powershell
# Ver el archivo en HDFS
docker exec namenode hdfs dfs -ls -h /spark-jars/

# Verificar configuraci√≥n
docker exec jupyter cat /opt/spark/conf/spark-defaults.conf | Select-String "yarn"
```

---

## ‚öôÔ∏è Configuraci√≥n YARN adicional

Tambi√©n se optimizaron recursos de YARN:

```properties
spark.yarn.am.memory    512m      # Memoria del Application Master
spark.yarn.am.cores     1         # Cores del Application Master
spark.executor.instances 2        # N√∫mero de executors
spark.executor.cores    1         # Cores por executor
```

Puedes ajustar estos valores seg√∫n tus necesidades en `config/spark-defaults.conf`.
