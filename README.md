# ğŸš€ Big Data Laboratorios Sophia - Cluster Hadoop & Spark

Este proyecto implementa un cluster completo de Big Data usando **Hadoop HDFS** y **Apache Spark** ejecutÃ¡ndose en contenedores **Debian 12** para el curso de Big Data de Sophia.

## ğŸ‘¥ Equipo de Desarrollo
- **Desarrollador Principal**: Diego Sanchez
- **Curso**: Big Data - 8vo Ciclo
- **InstituciÃ³n**: Sophia

## ğŸ—ï¸ Arquitectura del Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸŒ Interfaces Web                        â”‚
â”‚  Hadoop UI (9870) â”‚ Spark UI (8080) â”‚ Jupyter Lab (8888)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    âš¡ Capa de Procesamiento                  â”‚
â”‚          Spark Master â”€â”€â”€â”€â”€â”€â”€â”€ Spark Worker                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ’¾ Capa de Almacenamiento                â”‚
â”‚          NameNode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DataNode                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ï¿½ Requisitos Previos

### ğŸ–¥ï¸ Hardware MÃ­nimo
- **RAM**: 8GB (recomendado 16GB)
- **CPU**: 4 cores (recomendado 8 cores)  
- **Disco**: 50GB libres (para datos y contenedores)

### ğŸ’» Software Requerido
1. **Docker Desktop**: [Descargar aquÃ­](https://www.docker.com/products/docker-desktop/)
2. **Docker Compose**: (incluido con Docker Desktop)
3. **Git**: Para clonar el repositorio

### ğŸ”§ Verificar InstalaciÃ³n
```bash
# Verificar Docker
docker --version
docker-compose --version

# Verificar que Docker estÃ© ejecutÃ¡ndose
docker ps
```

## ğŸš€ GuÃ­a de InstalaciÃ³n Paso a Paso

### ğŸŒ **OpciÃ³n 1: GitHub Codespaces** (Recomendado - Sin instalaciÃ³n)

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/dsanchezchu/big-data-laboratorios-sophia)

1. **Click en el botÃ³n de arriba**
2. **Esperar 2-3 minutos** a que se configure
3. **Ejecutar**: `./setup.sh`
4. **Â¡Listo!** - Ver [GuÃ­a de Codespaces](CODESPACES.md)

### ğŸ’» **OpciÃ³n 2: InstalaciÃ³n Local**

### 1ï¸âƒ£ **Clonar el Repositorio**
```bash
git clone https://github.com/dsanchezchu/big-data-laboratorios-sophia.git
cd big-data-laboratorios-sophia
```

### 2ï¸âƒ£ **Construir las ImÃ¡genes** (Primera vez o despuÃ©s de cambios)
```bash
# Limpiar contenedores anteriores (opcional)
docker-compose down --volumes

# Construir imÃ¡genes (puede tardar 5-10 minutos la primera vez)
docker-compose build --no-cache
```

### 3ï¸âƒ£ **Iniciar el Cluster**
```bash
docker-compose up -d
```

### 4ï¸âƒ£ **Verificar que Todo Funcione**
```bash
# En Windows PowerShell
docker-compose ps

# En Linux/Mac
chmod +x test-cluster.sh
./test-cluster.sh
```

### 5ï¸âƒ£ **Acceder a las Interfaces**

| ğŸŒ Servicio | ğŸ“ URL | ğŸ“ DescripciÃ³n |
|-------------|--------|----------------|
| **Hadoop HDFS UI** | http://localhost:9870 | AdministraciÃ³n del sistema de archivos distribuido |
| **Spark Master UI** | http://localhost:8080 | Monitor del cluster Spark |
| **Spark Worker UI** | http://localhost:8081 | Estado del worker Spark |
| **Jupyter Lab** | http://localhost:8888 | Notebooks interactivos |

## ï¿½ Token de Jupyter

Para obtener el token de acceso a Jupyter:

### Windows PowerShell:
```powershell
docker-compose logs jupyter | Select-String -Pattern "token|http://"
```

### Linux/Mac:
```bash
docker-compose logs jupyter | grep -E "(token|http://)"
```

## ğŸ› ï¸ Componentes del Sistema

### ğŸ“¦ Contenedores Incluidos
- **NameNode**: Gestiona metadatos HDFS (Puerto 9870)
- **DataNode**: Almacena datos distribuidos  
- **Spark Master**: Coordinador de trabajos Spark (Puerto 8080)
- **Spark Worker**: Ejecutor de tareas Spark (Puerto 8081)
- **Jupyter Lab**: Entorno de desarrollo interactivo (Token requerido)

### ğŸ”§ TecnologÃ­as Utilizadas
- **Sistema Base**: Debian 12 (Bookworm)
- **Java**: OpenJDK 17
- **Hadoop**: 3.3.6
- **Spark**: 3.4.1
- **Python**: 3.11 con entorno virtual
- **Jupyter Lab**: Ãšltima versiÃ³n

## ğŸ“Š Ejemplos y Pruebas

### ğŸ§ª Prueba RÃ¡pida de HDFS
```bash
# Crear directorio en HDFS
docker exec namenode hdfs dfs -mkdir /test

# Subir archivo de prueba
echo "Hola Big Data Sophia!" | docker exec -i namenode hdfs dfs -put - /test/saludo.txt

# Leer archivo
docker exec namenode hdfs dfs -cat /test/saludo.txt

# Ver estructura de directorios
docker exec namenode hdfs dfs -ls /
```

### âš¡ Ejemplo con Spark + Jupyter
1. Abrir http://localhost:8888 e ingresar el token
2. Abrir el notebook `notebooks/ejemplo_elt.ipynb`
3. Ejecutar las celdas paso a paso
4. Ver resultados en tiempo real

### ğŸ“ˆ Verificar Estado del Cluster
```bash
# Estado de HDFS
docker exec namenode hdfs dfsadmin -report

# Estado de Spark
docker exec namenode hdfs dfs -ls /
```

## ğŸ”„ Escalabilidad del Cluster

### Para Agregar MÃ¡s DataNodes:
1. Editar `docker-compose.yml`:
```yaml
  datanode2:
    build: .
    container_name: datanode2
    hostname: datanode2
    # ... misma configuraciÃ³n que datanode1
```

2. Agregar volumen correspondiente:
```yaml
volumes:
  namenode_data:
  datanode1_data:
  datanode2_data:  # Nuevo
```

3. Reiniciar cluster:
```bash
docker-compose down
docker-compose up -d
```

## ğŸ› ï¸ Comandos Ãštiles de AdministraciÃ³n

### ğŸ³ Docker
```bash
# Ver logs de un servicio especÃ­fico
docker-compose logs -f namenode
docker-compose logs -f spark-master

# Reiniciar un servicio
docker-compose restart namenode

# Acceder a un contenedor
docker exec -it namenode bash
docker exec -it jupyter bash

# Ver recursos utilizados
docker stats
```

### ğŸ—„ï¸ HDFS
```bash
# Reportes del sistema
docker exec namenode hdfs dfsadmin -report
docker exec namenode hdfs dfsadmin -safemode get

# Operaciones con archivos
docker exec namenode hdfs dfs -ls /
docker exec namenode hdfs dfs -du -h /
docker exec namenode hdfs dfs -df -h
```

### âš¡ Spark
```bash
# Enviar trabajo Spark (ejemplo)
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --class org.apache.spark.examples.SparkPi \
  $SPARK_HOME/examples/jars/spark-examples_2.12-3.4.1.jar 10
```

## ğŸ†˜ ResoluciÃ³n de Problemas

### âŒ **Error: "pip externally-managed-environment"**
âœ… **SoluciÃ³n**: El proyecto usa entorno virtual automÃ¡ticamente. No requiere acciÃ³n.

### âŒ **Error: "Port already in use"**
âœ… **SoluciÃ³n**: 
```bash
docker-compose down
docker system prune -f
docker-compose up -d
```

### âŒ **Error: "Cannot connect to Spark Master"**
âœ… **SoluciÃ³n**: Esperar 2-3 minutos para que todos los servicios se inicien completamente.

### âŒ **Jupyter no muestra token**
âœ… **SoluciÃ³n**:
```bash
docker-compose restart jupyter
docker-compose logs jupyter | Select-String "token"
```

### âŒ **DataNode no se conecta al NameNode**
âœ… **SoluciÃ³n**:
```bash
# Formatear NameNode si es necesario
docker exec namenode hdfs namenode -format -force
docker-compose restart
```

## ğŸ§ª Estructura de Archivos del Proyecto

```
big-data-laboratorios-sophia/
â”œâ”€â”€ ğŸ“„ README.md                    # Esta guÃ­a
â”œâ”€â”€ ğŸ“„ .gitignore                   # Archivos ignorados por Git
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # OrquestaciÃ³n de servicios
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Imagen personalizada Debian + Hadoop + Spark
â”œâ”€â”€ ğŸ“„ test-cluster.sh              # Script de pruebas automatizadas
â”œâ”€â”€ ğŸ“ config/                      # Configuraciones
â”‚   â”œâ”€â”€ ğŸ“„ core-site.xml           # ConfiguraciÃ³n core de Hadoop
â”‚   â”œâ”€â”€ ğŸ“„ hdfs-site.xml           # ConfiguraciÃ³n HDFS
â”‚   â”œâ”€â”€ ğŸ“„ spark-defaults.conf     # ConfiguraciÃ³n por defecto de Spark
â”‚   â””â”€â”€ ğŸ“„ jupyter_notebook_config.py # ConfiguraciÃ³n de Jupyter
â”œâ”€â”€ ğŸ“ scripts/                     # Scripts de automatizaciÃ³n
â”‚   â”œâ”€â”€ ğŸ“„ start-services.sh       # Inicio de servicios
â”‚   â”œâ”€â”€ ğŸ“„ dynamic-datanodes.sh    # GestiÃ³n dinÃ¡mica de DataNodes
â”‚   â””â”€â”€ ğŸ“„ scale-cluster.sh        # Escalamiento del cluster
â””â”€â”€ ğŸ“ notebooks/                   # Jupyter notebooks
    â””â”€â”€ ğŸ“„ ejemplo_elt.ipynb       # Ejemplo de procesamiento ELT
```

## ğŸ¯ Casos de Uso AcadÃ©micos

### ğŸ“š **Para Estudiantes**
- Aprender conceptos de Big Data hands-on
- Experimentar con HDFS y operaciones distribuidas
- Desarrollar aplicaciones Spark en Python
- Comprender arquitecturas de cluster

### ğŸ‘¨â€ğŸ« **Para Profesores**
- Demostrar conceptos en tiempo real
- Asignar proyectos prÃ¡cticos
- Evaluar conocimientos con ejercicios reales
- Mostrar diferencias entre procesamiento local vs distribuido

### ğŸ”¬ **Para Proyectos**
- Prototipado de soluciones Big Data
- Testing de algoritmos distribuidos
- AnÃ¡lisis de datasets medianos (< 10GB)
- Desarrollo de pipelines ETL/ELT

## ğŸ¤ Contribuir al Proyecto

1. Fork del repositorio
2. Crear branch para nueva funcionalidad: `git checkout -b feature/nueva-funcionalidad`
3. Commit de cambios: `git commit -am 'Agregar nueva funcionalidad'`
4. Push al branch: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

## ğŸ“ Soporte y Contacto

- **Desarrollador**: Diego Sanchez
- **Email Institucional**: [Tu email aquÃ­]
- **Issues**: Reportar problemas en GitHub Issues
- **Discussiones**: Usar GitHub Discussions para preguntas

## ğŸ“„ Licencia

Este proyecto es para uso acadÃ©mico en el contexto del curso de Big Data de Sophia.

---

## ğŸ‰ Â¡Felicidades!

Si llegaste hasta aquÃ­ y todo funciona correctamente, ya tienes un cluster de Big Data completamente funcional. 

**Â¡Ahora puedes explorar el fascinante mundo del procesamiento distribuido!** ğŸš€

---

*Ãšltima actualizaciÃ³n: Septiembre 2025 - Diego Sanchez*