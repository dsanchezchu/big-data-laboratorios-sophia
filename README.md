# ğŸš€ Big Data Laboratorios Sophia - Cluster Hadoop & Spark con Apache NiFi

Este proyecto implementa un cluster completo de Big Data usando **Apache NiFi**, **Hadoop HDFS** y **Apache Spark** ejecutÃ¡ndose en contenedores para el curso de Big Data de Sophia.

## ğŸ‘¥ Equipo de Desarrollo
- **Desarrollador Principal**: Diego Sanchez
- **Curso**: Big Data - 8vo Ciclo
- **InstituciÃ³n**: Sophia

## ğŸ—ï¸ Arquitectura del Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ğŸŒ Interfaces Web                                 â”‚
â”‚  NiFi UI (8082) â”‚ Hadoop UI (9870) â”‚ Spark UI (8080) â”‚ Jupyter Lab (8888) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          âš¡ Capa de Procesamiento                           â”‚
â”‚              Spark Master â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Spark Worker                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ğŸ’¾ Capa de Almacenamiento                          â”‚
â”‚               NameNode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DataNode                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ğŸŒŠ Capa de Ingesta de Datos                        â”‚
â”‚                              Apache NiFi                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ï¿½ Requisitos Previos

### ğŸ–¥ï¸ Hardware MÃ­nimo
- **RAM**: 8GB (recomendado 16GB)
- **CPU**: 4 cores (recomendado 8 cores)  
- **Disco**: 50GB libres (para datos y contenedores)

### ğŸ’» Software Requerido
1. **Docker Desktop**: [Descargar aquÃ­](https://www.docker.com/products/docker-desktop/)
2. **Docker Compose**: (incluido con Docker Desktop)
3. **Git**: Para clonar el repositorio

### ğŸ”§ Verificar InstalaciÃ³n
```bash
# Verificar Docker
docker --version
docker-compose --version

# Verificar que Docker estÃ© ejecutÃ¡ndose
docker ps
```

## ğŸš€ GuÃ­a de InstalaciÃ³n Paso a Paso

### ğŸŒ **OpciÃ³n 1: GitHub Codespaces** (Recomendado - Sin instalaciÃ³n)

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/dsanchezchu/big-data-laboratorios-sophia)

1. **Click en el botÃ³n de arriba**
2. **Esperar 2-3 minutos** a que se configure
3. **Ejecutar**: `./setup.sh`
4. **Â¡Listo!** - Ver [GuÃ­a de Codespaces](CODESPACES.md)

### ğŸ’» **OpciÃ³n 2: InstalaciÃ³n Local**

### 1ï¸âƒ£ **Clonar el Repositorio**
```bash
git clone https://github.com/dsanchezchu/big-data-laboratorios-sophia.git
cd big-data-laboratorios-sophia
```

### 2ï¸âƒ£ **Construir las ImÃ¡genes** (Primera vez o despuÃ©s de cambios)
```bash
# Limpiar contenedores anteriores (opcional)
docker-compose down --volumes

# Construir imÃ¡genes (puede tardar 5-10 minutos la primera vez)
docker-compose build --no-cache
```

### 3ï¸âƒ£ **Iniciar el Cluster**
```bash
docker-compose up -d
```

### 4ï¸âƒ£ **Verificar que Todo Funcione**
```bash
# En Windows PowerShell
docker-compose ps

# En Linux/Mac
chmod +x test-cluster.sh
./test-cluster.sh
```

### 5ï¸âƒ£ **Acceder a las Interfaces**

| ğŸŒ Servicio | ğŸ“ URL | ğŸ“ DescripciÃ³n |
|-------------|--------|----------------|
| **ğŸŒŠ Apache NiFi UI** | http://localhost:8082 | Ingesta y procesamiento de flujos de datos |
| **ğŸ’¾ Hadoop HDFS UI** | http://localhost:9870 | AdministraciÃ³n del sistema de archivos distribuido |
| **âš¡ Spark Master UI** | http://localhost:8080 | Monitor del cluster Spark |
| **ğŸ”§ Spark Worker UI** | http://localhost:8081 | Estado del worker Spark |
| **ğŸ“Š Jupyter Lab** | http://localhost:8888 | Notebooks interactivos |

## ğŸ”‘ Credenciales de Acceso

### ğŸŒŠ Apache NiFi
- **Usuario**: `admin`
- **ContraseÃ±a**: `ctsBtRBKHRAx69EqUghvvgEvjnaLjFEB`
- **URL**: http://localhost:8082

### ğŸ“Š Token de Jupyter

Para obtener el token de acceso a Jupyter:

### Windows PowerShell:
```powershell
docker-compose logs jupyter | Select-String -Pattern "token|http://"
```

### Linux/Mac:
```bash
docker-compose logs jupyter | grep -E "(token|http://)"
```

## ğŸ› ï¸ Componentes del Sistema

### ğŸ“¦ Contenedores Incluidos
- **ğŸŒŠ Apache NiFi**: Ingesta y procesamiento de flujos de datos (Puerto 8082)
- **ğŸ’¾ NameNode**: Gestiona metadatos HDFS (Puerto 9870)
- **ğŸ’¾ DataNode**: Almacena datos distribuidos  
- **âš¡ Spark Master**: Coordinador de trabajos Spark (Puerto 8080)
- **âš¡ Spark Worker**: Ejecutor de tareas Spark (Puerto 8081)
- **ğŸ“Š Jupyter Lab**: Entorno de desarrollo interactivo (Token requerido)

### ğŸ”§ TecnologÃ­as Utilizadas
- **Sistema Base**: Debian 12 (Bookworm) para servicios Hadoop/Spark
- **Ingesta de Datos**: Apache NiFi 1.23.2
- **Java**: OpenJDK 17
- **Almacenamiento Distribuido**: Hadoop HDFS 3.3.6
- **Procesamiento Distribuido**: Apache Spark 3.4.1
- **AnÃ¡lisis Interactivo**: Python 3.11 con Jupyter Lab
- **ContenedorizaciÃ³n**: Docker & Docker Compose

## ğŸ“Š Ejemplos y Flujos de Datos

### ğŸŒŠ **Flujo Completo: NiFi â†’ HDFS â†’ Spark â†’ Jupyter**

#### **1. Preparar Datos de Entrada**
```bash
# Crear archivos de ejemplo en el directorio de datos
echo "id,name,age,city
1,Juan,25,Madrid
2,Maria,30,Barcelona
3,Carlos,28,Valencia" > ./data/sample_users.csv
```

#### **2. Configurar Flujo en NiFi**
1. **Acceder a NiFi**: http://localhost:8082
2. **Iniciar sesiÃ³n** con las credenciales proporcionadas
3. **Crear procesadores**:
   - `GetFile`: Leer archivos de `./data/input/`
   - `ConvertRecord`: Convertir CSV a JSON
   - `PutHDFS`: Escribir a HDFS en `/data/processed/`

#### **3. ConfiguraciÃ³n de Procesadores NiFi**

**GetFile Processor:**
```
Input Directory: /opt/nifi/nifi-current/data
File Filter: .*\.csv
Keep Source File: false
```

**PutHDFS Processor:**
```
Hadoop Configuration Resources: (dejar vacÃ­o)
Directory: /data/nifi_processed
Additional Classpath Resources: (dejar vacÃ­o)
```

### ğŸ§ª **Prueba RÃ¡pida de HDFS**
```bash
# Crear directorio en HDFS
docker exec namenode hdfs dfs -mkdir /test

# Subir archivo de prueba
echo "Hola Big Data Sophia!" | docker exec -i namenode hdfs dfs -put - /test/saludo.txt

# Leer archivo
docker exec namenode hdfs dfs -cat /test/saludo.txt

# Ver estructura de directorios
docker exec namenode hdfs dfs -ls /
```

### âš¡ **Ejemplo con Spark + Jupyter**
1. Abrir http://localhost:8888 e ingresar el token
2. Crear nuevo notebook de Python
3. Ejecutar cÃ³digo para leer datos procesados por NiFi:
```python
from pyspark.sql import SparkSession

# Crear sesiÃ³n Spark
spark = SparkSession.builder \
    .appName("NiFi-HDFS-Analysis") \
    .master("spark://spark-master:7077") \
    .getOrCreate()

# Leer datos desde HDFS
df = spark.read.json("hdfs://namenode:9000/data/nifi_processed/*.json")
df.show()

# AnÃ¡lisis bÃ¡sico
df.groupBy("city").count().show()
```

### ğŸ“ˆ **Verificar Estado Completo del Cluster**
```bash
# Verificar estado de todos los servicios
docker-compose ps

# Estado de HDFS (deberÃ­a mostrar 2 DataNodes)
docker exec namenode hdfs dfsadmin -report

# Ver archivos procesados por NiFi en HDFS
docker exec namenode hdfs dfs -ls /data/

# Verificar logs de NiFi
docker logs nifi --tail 20

# Estado de Spark Master
curl http://localhost:8080
```

## ğŸ”„ Escalabilidad del Cluster

### Para Agregar MÃ¡s DataNodes:
1. Editar `docker-compose.yml`:
```yaml
  datanode2:
    build: .
    container_name: datanode2
    hostname: datanode2
    # ... misma configuraciÃ³n que datanode1
```

2. Agregar volumen correspondiente:
```yaml
volumes:
  namenode_data:
  datanode1_data:
  datanode2_data:  # Nuevo
```

3. Reiniciar cluster:
```bash
docker-compose down
docker-compose up -d
```

## ğŸ› ï¸ Comandos Ãštiles de AdministraciÃ³n

### ğŸ³ Docker
```bash
# Ver logs de servicios especÃ­ficos
docker-compose logs -f namenode
docker-compose logs -f nifi
docker-compose logs -f spark-master

# Reiniciar un servicio
docker-compose restart nifi
docker-compose restart namenode

# Acceder a un contenedor
docker exec -it namenode bash
docker exec -it nifi bash
docker exec -it jupyter bash

# Ver recursos utilizados
docker stats
```

### ğŸŒŠ NiFi
```bash
# Ver logs de NiFi
docker logs nifi

# Reiniciar solo NiFi
docker-compose restart nifi

# Acceder al directorio de datos de NiFi
docker exec -it nifi ls -la /opt/nifi/nifi-current/data

# Ver procesadores activos (desde dentro del contenedor)
docker exec -it nifi curl http://localhost:8080/nifi-api/flow/process-groups/root
```

### ğŸ—„ï¸ HDFS
```bash
# Reportes del sistema
docker exec namenode hdfs dfsadmin -report
docker exec namenode hdfs dfsadmin -safemode get

# Operaciones con archivos
docker exec namenode hdfs dfs -ls /
docker exec namenode hdfs dfs -du -h /
docker exec namenode hdfs dfs -df -h
```

### âš¡ Spark
```bash
# Enviar trabajo Spark (ejemplo)
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --class org.apache.spark.examples.SparkPi \
  $SPARK_HOME/examples/jars/spark-examples_2.12-3.4.1.jar 10
```

## ğŸ†˜ ResoluciÃ³n de Problemas

### âŒ **Error: "NiFi UI no carga"**
âœ… **SoluciÃ³n**: 
```bash
# Verificar estado de NiFi
docker logs nifi --tail 50

# Reiniciar NiFi si es necesario
docker-compose restart nifi

# Esperar 2-3 minutos para inicializaciÃ³n completa
```

### âŒ **Error: "pip externally-managed-environment"**
âœ… **SoluciÃ³n**: El proyecto usa entorno virtual automÃ¡ticamente. No requiere acciÃ³n.

### âŒ **Error: "Port already in use"**
âœ… **SoluciÃ³n**: 
```bash
docker-compose down
docker system prune -f
docker-compose up -d
```

### âŒ **Error: "Cannot connect to Spark Master"**
âœ… **SoluciÃ³n**: Esperar 2-3 minutos para que todos los servicios se inicien completamente.

### âŒ **Jupyter no muestra token**
âœ… **SoluciÃ³n**:
```bash
docker-compose restart jupyter
docker-compose logs jupyter | Select-String "token"
```

### âŒ **NiFi no puede conectar con HDFS**
âœ… **SoluciÃ³n**:
```bash
# Verificar que HDFS estÃ© funcionando
docker exec namenode hdfs dfsadmin -safemode get

# En NiFi UI, configurar PutHDFS processor:
# - Hadoop Configuration Resources: (dejar vacÃ­o)
# - Directory: /data/nifi_processed
# - No configurar Kerberos ni autenticaciÃ³n adicional
```

### âŒ **DataNode no se conecta al NameNode**
âœ… **SoluciÃ³n**:
```bash
# Formatear NameNode si es necesario
docker exec namenode hdfs namenode -format -force
docker-compose restart
```

## ğŸ§ª Estructura de Archivos del Proyecto

```
big-data-laboratorios-sophia/
â”œâ”€â”€ ğŸ“„ README.md                    # Esta guÃ­a
â”œâ”€â”€ ğŸ“„ .gitignore                   # Archivos ignorados por Git
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # OrquestaciÃ³n de servicios con NiFi
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Imagen personalizada Debian + Hadoop + Spark
â”œâ”€â”€ ğŸ“„ NIFI-GUIDE.md                # GuÃ­a especÃ­fica de Apache NiFi
â”œâ”€â”€ ğŸ“ config/                      # Configuraciones
â”‚   â”œâ”€â”€ ğŸ“„ core-site.xml           # ConfiguraciÃ³n core de Hadoop
â”‚   â”œâ”€â”€ ğŸ“„ hdfs-site.xml           # ConfiguraciÃ³n HDFS
â”‚   â”œâ”€â”€ ğŸ“„ spark-defaults.conf     # ConfiguraciÃ³n por defecto de Spark
â”‚   â””â”€â”€ ğŸ“„ jupyter_notebook_config.py # ConfiguraciÃ³n de Jupyter
â”œâ”€â”€ ğŸ“ scripts/                     # Scripts de automatizaciÃ³n
â”‚   â”œâ”€â”€ ğŸ“„ start-services-fixed.sh # Inicio de servicios mejorado
â”‚   â”œâ”€â”€ ğŸ“„ start-nifi.sh           # Script especÃ­fico para NiFi
â”‚   â””â”€â”€ ğŸ“„ verify-stack-nifi.ps1   # VerificaciÃ³n del stack completo
â”œâ”€â”€ ğŸ“ data/                        # Datos de entrada para NiFi
â”‚   â”œâ”€â”€ ğŸ“ input/                   # Archivos de entrada
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_users.csv    # Datos de ejemplo CSV
â”‚   â”‚   â””â”€â”€ ğŸ“„ sample_logs.json    # Logs de ejemplo JSON
â”‚   â””â”€â”€ ğŸ“ processed/               # Archivos procesados
â””â”€â”€ ğŸ“ notebooks/                   # Jupyter notebooks
    â””â”€â”€ ğŸ“„ ejemplo_elt.ipynb       # Ejemplo de procesamiento ELT
```

## ğŸ¯ Casos de Uso AcadÃ©micos

### ğŸ“š **Para Estudiantes**
- Aprender conceptos de Big Data hands-on
- Experimentar con ingesta de datos usando NiFi
- Comprender flujos ETL/ELT completos
- Desarrollar aplicaciones Spark en Python
- Practicar con sistemas distribuidos reales

### ğŸ‘¨â€ğŸ« **Para Profesores**
- Demostrar pipelines de datos completos en tiempo real
- EnseÃ±ar arquitecturas modernas de Big Data
- Mostrar integraciÃ³n entre diferentes tecnologÃ­as
- Asignar proyectos de anÃ¡lisis de datos a gran escala
- Evaluar competencias en ecosistemas Big Data

### ğŸ”¬ **Para Proyectos**
- Prototipado de soluciones de ingesta masiva de datos
- Desarrollo de pipelines ETL/ELT robustos
- AnÃ¡lisis de datasets medianos a grandes (GB a TB)
- Testing de arquitecturas distribuidas
- ImplementaciÃ³n de data lakes modernos

## ğŸ¤ Contribuir al Proyecto

1. Fork del repositorio
2. Crear branch para nueva funcionalidad: `git checkout -b feature/nueva-funcionalidad`
3. Commit de cambios: `git commit -am 'Add: Nueva funcionalidad de [descripciÃ³n]'`
4. Push al branch: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

### ğŸ·ï¸ **Convenciones de Commits**
- `Add:` Nueva funcionalidad
- `Fix:` CorrecciÃ³n de errores
- `Update:` ActualizaciÃ³n de documentaciÃ³n o configuraciÃ³n
- `Refactor:` RefactorizaciÃ³n de cÃ³digo
- `Remove:` EliminaciÃ³n de cÃ³digo o archivos

## ğŸ“ Soporte y Contacto

- **Desarrollador**: Diego Sanchez
- **Email Institucional**: [Tu email aquÃ­]
- **Issues**: Reportar problemas en GitHub Issues
- **Discussiones**: Usar GitHub Discussions para preguntas

## ğŸ“„ Licencia

Este proyecto es para uso acadÃ©mico en el contexto del curso de Big Data de Sophia.

---

## ğŸ‰ Â¡Felicidades!

Si llegaste hasta aquÃ­ y todo funciona correctamente, ya tienes un **cluster completo de Big Data con Apache NiFi** totalmente operativo. 

### ğŸŒŠ **Tu Stack Incluye:**
- **Ingesta de Datos**: Apache NiFi para capturar y transformar datos
- **Almacenamiento Distribuido**: Hadoop HDFS para big data
- **Procesamiento Distribuido**: Apache Spark para anÃ¡lisis a gran escala  
- **AnÃ¡lisis Interactivo**: Jupyter Lab para data science

**Â¡Ahora puedes construir pipelines de datos modernos y explorar el fascinante mundo del Big Data!** ğŸš€

---

*Ãšltima actualizaciÃ³n: Septiembre 2025 - Diego Sanchez*  
*VersiÃ³n 2.0 - Con integraciÃ³n Apache NiFi*