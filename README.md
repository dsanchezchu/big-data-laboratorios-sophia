# üöÄ Big Data Laboratorios Sophia - Cluster Hadoop & Spark con Apache NiFi

Este proyecto implementa un cluster completo de Big Data usando **Apache NiFi**, **Hadoop HDFS** y **Apache Spark** ejecut√°ndose en contenedores para el curso de Big Data de Sophia.

## üë• Equipo de Desarrollo
- **Desarrollador Principal**: Diego Sanchez
- **Curso**: Big Data - 8vo Ciclo
- **Instituci√≥n**: Sophia

## üèóÔ∏è Arquitectura del Cluster

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           üåê Interfaces Web                                 ‚îÇ
‚îÇ  NiFi UI (8082) ‚îÇ Hadoop UI (9870) ‚îÇ Spark UI (8080) ‚îÇ Jupyter Lab (8888) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          ‚ö° Capa de Procesamiento                           ‚îÇ
‚îÇ              Spark Master ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Spark Worker                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          üíæ Capa de Almacenamiento                          ‚îÇ
‚îÇ               NameNode ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ DataNode                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          üåä Capa de Ingesta de Datos                        ‚îÇ
‚îÇ                              Apache NiFi                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ÔøΩ Requisitos Previos

### üñ•Ô∏è Hardware M√≠nimo
- **RAM**: 8GB (recomendado 16GB)
- **CPU**: 4 cores (recomendado 8 cores)  
- **Disco**: 50GB libres (para datos y contenedores)

### üíª Software Requerido
1. **Docker Desktop**: [Descargar aqu√≠](https://www.docker.com/products/docker-desktop/)
2. **Docker Compose**: (incluido con Docker Desktop)
3. **Git**: Para clonar el repositorio

### üîß Verificar Instalaci√≥n
```bash
# Verificar Docker
docker --version
docker-compose --version

# Verificar que Docker est√© ejecut√°ndose
docker ps
```

## üöÄ Gu√≠a de Instalaci√≥n Paso a Paso

### üåê **Opci√≥n 1: GitHub Codespaces** (Recomendado - Sin instalaci√≥n)

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/dsanchezchu/big-data-laboratorios-sophia)

1. **Click en el bot√≥n de arriba**
2. **Esperar 2-3 minutos** a que se configure
3. **Ejecutar**: `./setup.sh`
4. **¬°Listo!** - Ver [Gu√≠a de Codespaces](CODESPACES.md)

### üíª **Opci√≥n 2: Instalaci√≥n Local**

### 1Ô∏è‚É£ **Clonar el Repositorio**
```bash
git clone https://github.com/dsanchezchu/big-data-laboratorios-sophia.git
cd big-data-laboratorios-sophia
```

### 2Ô∏è‚É£ **Construir las Im√°genes** (Primera vez o despu√©s de cambios)
```bash
# Limpiar contenedores anteriores (opcional)
docker-compose down --volumes

# Construir im√°genes (puede tardar 5-10 minutos la primera vez)
docker-compose build --no-cache
```

### 3Ô∏è‚É£ **Iniciar el Cluster**
```bash
docker-compose up -d
```

### 4Ô∏è‚É£ **Verificar que Todo Funcione**
```bash
# En Windows PowerShell
docker-compose ps

# En Linux/Mac
chmod +x test-cluster.sh
./test-cluster.sh
```

### 5Ô∏è‚É£ **Acceder a las Interfaces**

| üåê Servicio | üìç URL | üìù Descripci√≥n |
|-------------|--------|----------------|
| **üåä Apache NiFi UI** | http://localhost:8082 | Ingesta y procesamiento de flujos de datos |
| **üíæ Hadoop HDFS UI** | http://localhost:9870 | Administraci√≥n del sistema de archivos distribuido |
| **‚ö° Spark Master UI** | http://localhost:8080 | Monitor del cluster Spark |
| **üîß Spark Worker UI** | http://localhost:8081 | Estado del worker Spark |
| **üìä Jupyter Lab** | http://localhost:8888 | Notebooks interactivos |

## üîë Credenciales de Acceso

### üåä Apache NiFi
- **Usuario**: `admin`
- **Contrase√±a**: `ctsBtRBKHRAx69EqUghvvgEvjnaLjFEB`
- **URL**: http://localhost:8082

### üìä Token de Jupyter

Para obtener el token de acceso a Jupyter:

### Windows PowerShell:
```powershell
docker-compose logs jupyter | Select-String -Pattern "token|http://"
```

### Linux/Mac:
```bash
docker-compose logs jupyter | grep -E "(token|http://)"
```

## üõ†Ô∏è Componentes del Sistema

### üì¶ Contenedores Incluidos
- **üåä Apache NiFi**: Ingesta y procesamiento de flujos de datos (Puerto 8082)
- **üíæ NameNode**: Gestiona metadatos HDFS (Puerto 9870)
- **üíæ DataNode**: Almacena datos distribuidos  
- **‚ö° Spark Master**: Coordinador de trabajos Spark (Puerto 8080)
- **‚ö° Spark Worker**: Ejecutor de tareas Spark (Puerto 8081)
- **üìä Jupyter Lab**: Entorno de desarrollo interactivo (Token requerido)

### üîß Tecnolog√≠as Utilizadas
- **Sistema Base**: Debian 12 (Bookworm) para servicios Hadoop/Spark
- **Ingesta de Datos**: Apache NiFi 1.23.2
- **Java**: OpenJDK 17
- **Almacenamiento Distribuido**: Hadoop HDFS 3.3.6
- **Procesamiento Distribuido**: Apache Spark 3.4.1
- **An√°lisis Interactivo**: Python 3.11 con Jupyter Lab
- **Contenedorizaci√≥n**: Docker & Docker Compose

## üìä Ejemplos y Flujos de Datos

### üåä **Flujo Completo: NiFi ‚Üí HDFS ‚Üí Spark ‚Üí Jupyter**

#### **1. Preparar Datos de Entrada**
```bash
# Crear archivos de ejemplo en el directorio de datos
echo "id,name,age,city
1,Juan,25,Madrid
2,Maria,30,Barcelona
3,Carlos,28,Valencia" > ./data/sample_users.csv
```

#### **2. Configurar Flujo en NiFi**
1. **Acceder a NiFi**: http://localhost:8082
2. **Iniciar sesi√≥n** con las credenciales proporcionadas
3. **Crear procesadores**:
   - `GetFile`: Leer archivos de `./data/input/`
   - `ConvertRecord`: Convertir CSV a JSON
   - `PutHDFS`: Escribir a HDFS en `/data/processed/`

#### **3. Configuraci√≥n de Procesadores NiFi**

**GetFile Processor:**
```
Input Directory: /opt/nifi/nifi-current/data
File Filter: .*\.csv
Keep Source File: false
```

**PutHDFS Processor:**
```
Hadoop Configuration Resources: (dejar vac√≠o)
Directory: /data/nifi_processed
Additional Classpath Resources: (dejar vac√≠o)
```

### üß™ **Prueba R√°pida de HDFS**
```bash
# Crear directorio en HDFS
docker exec namenode hdfs dfs -mkdir /test

# Subir archivo de prueba
echo "Hola Big Data Sophia!" | docker exec -i namenode hdfs dfs -put - /test/saludo.txt

# Leer archivo
docker exec namenode hdfs dfs -cat /test/saludo.txt

# Ver estructura de directorios
docker exec namenode hdfs dfs -ls /
```

### ‚ö° **Ejemplo con Spark + Jupyter**
1. Abrir http://localhost:8888 e ingresar el token
2. Crear nuevo notebook de Python
3. Ejecutar c√≥digo para leer datos procesados por NiFi:
```python
from pyspark.sql import SparkSession

# Crear sesi√≥n Spark
spark = SparkSession.builder \
    .appName("NiFi-HDFS-Analysis") \
    .master("spark://spark-master:7077") \
    .getOrCreate()

# Leer datos desde HDFS
df = spark.read.json("hdfs://namenode:9000/data/nifi_processed/*.json")
df.show()

# An√°lisis b√°sico
df.groupBy("city").count().show()
```

### üìà **Verificar Estado Completo del Cluster**
```bash
# Verificar estado de todos los servicios
docker-compose ps

# Estado de HDFS (deber√≠a mostrar 2 DataNodes)
docker exec namenode hdfs dfsadmin -report

# Ver archivos procesados por NiFi en HDFS
docker exec namenode hdfs dfs -ls /data/

# Verificar logs de NiFi
docker logs nifi --tail 20

# Estado de Spark Master
curl http://localhost:8080
```

## üîÑ Escalabilidad del Cluster

### Para Agregar M√°s DataNodes:
1. Editar `docker-compose.yml`:
```yaml
  datanode2:
    build: .
    container_name: datanode2
    hostname: datanode2
    # ... misma configuraci√≥n que datanode1
```

2. Agregar volumen correspondiente:
```yaml
volumes:
  namenode_data:
  datanode1_data:
  datanode2_data:  # Nuevo
```

3. Reiniciar cluster:
```bash
docker-compose down
docker-compose up -d
```

## üõ†Ô∏è Comandos √ötiles de Administraci√≥n

### üê≥ Docker
```bash
# Ver logs de servicios espec√≠ficos
docker-compose logs -f namenode
docker-compose logs -f nifi
docker-compose logs -f spark-master

# Reiniciar un servicio
docker-compose restart nifi
docker-compose restart namenode

# Acceder a un contenedor
docker exec -it namenode bash
docker exec -it nifi bash
docker exec -it jupyter bash

# Ver recursos utilizados
docker stats
```

### üåä NiFi
```bash
# Ver logs de NiFi
docker logs nifi

# Reiniciar solo NiFi
docker-compose restart nifi

# Acceder al directorio de datos de NiFi
docker exec -it nifi ls -la /opt/nifi/nifi-current/data

# Ver procesadores activos (desde dentro del contenedor)
docker exec -it nifi curl http://localhost:8080/nifi-api/flow/process-groups/root
```

### üóÑÔ∏è HDFS
```bash
# Reportes del sistema
docker exec namenode hdfs dfsadmin -report
docker exec namenode hdfs dfsadmin -safemode get

# Operaciones con archivos
docker exec namenode hdfs dfs -ls /
docker exec namenode hdfs dfs -du -h /
docker exec namenode hdfs dfs -df -h
```

### ‚ö° Spark
```bash
# Enviar trabajo Spark (ejemplo)
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --class org.apache.spark.examples.SparkPi \
  $SPARK_HOME/examples/jars/spark-examples_2.12-3.4.1.jar 10
```

## üÜò Resoluci√≥n de Problemas

### ‚ùå **Error: "NiFi UI no carga"**
‚úÖ **Soluci√≥n**: 
```bash
# Verificar estado de NiFi
docker logs nifi --tail 50

# Reiniciar NiFi si es necesario
docker-compose restart nifi

# Esperar 2-3 minutos para inicializaci√≥n completa
```

### ‚ùå **Error: "pip externally-managed-environment"**
‚úÖ **Soluci√≥n**: El proyecto usa entorno virtual autom√°ticamente. No requiere acci√≥n.

### ‚ùå **Error: "Port already in use"**
‚úÖ **Soluci√≥n**: 
```bash
docker-compose down
docker system prune -f
docker-compose up -d
```

### ‚ùå **Error: "Cannot connect to Spark Master"**
‚úÖ **Soluci√≥n**: Esperar 2-3 minutos para que todos los servicios se inicien completamente.

### ‚ùå **Jupyter no muestra token**
‚úÖ **Soluci√≥n**:
```bash
docker-compose restart jupyter
docker-compose logs jupyter | Select-String "token"
```

### ‚ùå **NiFi no puede conectar con HDFS**
‚úÖ **Soluci√≥n**:
```bash
# Verificar que HDFS est√© funcionando
docker exec namenode hdfs dfsadmin -safemode get

# En NiFi UI, configurar PutHDFS processor:
# - Hadoop Configuration Resources: (dejar vac√≠o)
# - Directory: /data/nifi_processed
# - No configurar Kerberos ni autenticaci√≥n adicional
```

### ‚ùå **DataNode no se conecta al NameNode**
‚úÖ **Soluci√≥n**:
```bash
# Formatear NameNode si es necesario
docker exec namenode hdfs namenode -format -force
docker-compose restart
```

## üß™ Estructura de Archivos del Proyecto

```
big-data-laboratorios-sophia/
‚îú‚îÄ‚îÄ üìÑ README.md                    # Esta gu√≠a
‚îú‚îÄ‚îÄ üìÑ .gitignore                   # Archivos ignorados por Git
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml           # Orquestaci√≥n de servicios con NiFi
‚îú‚îÄ‚îÄ üìÑ Dockerfile                   # Imagen personalizada Debian + Hadoop + Spark
‚îú‚îÄ‚îÄ üìÑ NIFI-GUIDE.md                # Gu√≠a espec√≠fica de Apache NiFi
‚îú‚îÄ‚îÄ üìÅ config/                      # Configuraciones
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ core-site.xml           # Configuraci√≥n core de Hadoop
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ hdfs-site.xml           # Configuraci√≥n HDFS
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ spark-defaults.conf     # Configuraci√≥n por defecto de Spark
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ jupyter_notebook_config.py # Configuraci√≥n de Jupyter
‚îú‚îÄ‚îÄ üìÅ scripts/                     # Scripts de automatizaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ start-services-fixed.sh # Inicio de servicios mejorado
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ start-nifi.sh           # Script espec√≠fico para NiFi
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ verify-stack-nifi.ps1   # Verificaci√≥n del stack completo
‚îú‚îÄ‚îÄ üìÅ data/                        # Datos de entrada para NiFi
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ input/                   # Archivos de entrada
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ sample_users.csv    # Datos de ejemplo CSV
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ sample_logs.json    # Logs de ejemplo JSON
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ processed/               # Archivos procesados
‚îî‚îÄ‚îÄ üìÅ notebooks/                   # Jupyter notebooks
    ‚îî‚îÄ‚îÄ üìÑ ejemplo_elt.ipynb       # Ejemplo de procesamiento ELT
```

## üéØ Casos de Uso Acad√©micos

### üìö **Para Estudiantes**
- Aprender conceptos de Big Data hands-on
- Experimentar con ingesta de datos usando NiFi
- Comprender flujos ETL/ELT completos
- Desarrollar aplicaciones Spark en Python
- Practicar con sistemas distribuidos reales

### üë®‚Äçüè´ **Para Profesores**
- Demostrar pipelines de datos completos en tiempo real
- Ense√±ar arquitecturas modernas de Big Data
- Mostrar integraci√≥n entre diferentes tecnolog√≠as
- Asignar proyectos de an√°lisis de datos a gran escala
- Evaluar competencias en ecosistemas Big Data

### üî¨ **Para Proyectos**
- Prototipado de soluciones de ingesta masiva de datos
- Desarrollo de pipelines ETL/ELT robustos
- An√°lisis de datasets medianos a grandes (GB a TB)
- Testing de arquitecturas distribuidas
- Implementaci√≥n de data lakes modernos

## ü§ù Contribuir al Proyecto

1. Fork del repositorio
2. Crear branch para nueva funcionalidad: `git checkout -b feature/nueva-funcionalidad`
3. Commit de cambios: `git commit -am 'Add: Nueva funcionalidad de [descripci√≥n]'`
4. Push al branch: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

### üè∑Ô∏è **Convenciones de Commits**
- `Add:` Nueva funcionalidad
- `Fix:` Correcci√≥n de errores
- `Update:` Actualizaci√≥n de documentaci√≥n o configuraci√≥n
- `Refactor:` Refactorizaci√≥n de c√≥digo
- `Remove:` Eliminaci√≥n de c√≥digo o archivos

## üìû Soporte y Contacto

- **Desarrollador**: Diego Sanchez
- **Email Institucional**: [Tu email aqu√≠]
- **Issues**: Reportar problemas en GitHub Issues
- **Discussiones**: Usar GitHub Discussions para preguntas

## üìÑ Licencia

Este proyecto es para uso acad√©mico en el contexto del curso de Big Data de Sophia.

---

## üéâ ¬°Felicidades!

Si llegaste hasta aqu√≠ y todo funciona correctamente, ya tienes un **cluster completo de Big Data con Apache NiFi** totalmente operativo. 

### üåä **Tu Stack Incluye:**
- **Ingesta de Datos**: Apache NiFi para capturar y transformar datos
- **Almacenamiento Distribuido**: Hadoop HDFS para big data
- **Procesamiento Distribuido**: Apache Spark para an√°lisis a gran escala  
- **An√°lisis Interactivo**: Jupyter Lab para data science

**¬°Ahora puedes construir pipelines de datos modernos y explorar el fascinante mundo del Big Data!** üöÄ

---

*√öltima actualizaci√≥n: Septiembre 2025 - Diego Sanchez*  
*Versi√≥n 2.0 - Con integraci√≥n Apache NiFi*